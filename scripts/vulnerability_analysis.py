"""
Vulnerability Index Calculation
Calculates state-wise agricultural vulnerability to climate change
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os

def load_data():
    """Load processed data"""
    print("Loading data...")
    merged_df = pd.read_csv('./data/processed/merged_data.csv')
    print(f"✓ Loaded {len(merged_df):,} records")
    return merged_df

def calculate_exposure(df):
    """Calculate climate change exposure (trend in climate variables)"""
    print("\nCalculating exposure scores...")
    
    def calc_trend(group, col):
        """Calculate linear trend slope"""
        if len(group) < 2:
            return 0
        return np.polyfit(group['Year'], group[col], 1)[0]
    
    exposure_data = []
    
    for state in df['State'].unique():
        state_data = df[df['State'] == state]
        
        # Calculate trends
        temp_trend = calc_trend(state_data, 'Avg_Temp_C')
        rain_trend = calc_trend(state_data, 'Rainfall_mm')
        
        # Calculate variability (coefficient of variation)
        temp_cv = state_data['Avg_Temp_C'].std() / state_data['Avg_Temp_C'].mean()
        rain_cv = state_data['Rainfall_mm'].std() / state_data['Rainfall_mm'].mean()
        
        exposure_data.append({
            'State': state,
            'Temp_Trend': temp_trend,
            'Rain_Trend': rain_trend,
            'Temp_Variability': temp_cv,
            'Rain_Variability': rain_cv
        })
    
    exposure_df = pd.DataFrame(exposure_data)
    
    # Normalize to 0-1 scale
    exposure_df['Temp_Trend_Norm'] = (exposure_df['Temp_Trend'] - exposure_df['Temp_Trend'].min()) / \
                                      (exposure_df['Temp_Trend'].max() - exposure_df['Temp_Trend'].min())
    
    exposure_df['Rain_Variability_Norm'] = (exposure_df['Rain_Variability'] - exposure_df['Rain_Variability'].min()) / \
                                            (exposure_df['Rain_Variability'].max() - exposure_df['Rain_Variability'].min())
    
    # Combined exposure score
    exposure_df['Exposure_Score'] = (exposure_df['Temp_Trend_Norm'] + exposure_df['Rain_Variability_Norm']) / 2
    
    print(f"✓ Exposure scores calculated for {len(exposure_df)} states")
    return exposure_df

def calculate_sensitivity(df):
    """Calculate sensitivity (yield dependence on climate)"""
    print("Calculating sensitivity scores...")
    
    sensitivity_data = []
    
    for state in df['State'].unique():
        state_data = df[df['State'] == state]
        
        # Calculate correlation between climate and yield
        correlations = []
        
        for crop in state_data['Crop'].unique():
            crop_data = state_data[state_data['Crop'] == crop]
            
            if len(crop_data) > 10:
                # Correlation with rainfall
                rain_corr = abs(crop_data['Rainfall_mm'].corr(crop_data['Yield_ton_per_ha']))
                # Correlation with temperature
                temp_corr = abs(crop_data['Avg_Temp_C'].corr(crop_data['Yield_ton_per_ha']))
                
                correlations.append((rain_corr + temp_corr) / 2)
        
        avg_correlation = np.mean(correlations) if correlations else 0
        
        sensitivity_data.append({
            'State': state,
            'Climate_Yield_Correlation': avg_correlation
        })
    
    sensitivity_df = pd.DataFrame(sensitivity_data)
    
    # Normalize
    sensitivity_df['Sensitivity_Score'] = (sensitivity_df['Climate_Yield_Correlation'] - 
                                           sensitivity_df['Climate_Yield_Correlation'].min()) / \
                                          (sensitivity_df['Climate_Yield_Correlation'].max() - 
                                           sensitivity_df['Climate_Yield_Correlation'].min())
    
    print(f"✓ Sensitivity scores calculated for {len(sensitivity_df)} states")
    return sensitivity_df

def calculate_adaptive_capacity(df):
    """Calculate adaptive capacity (yield stability and growth)"""
    print("Calculating adaptive capacity scores...")
    
    capacity_data = []
    
    for state in df['State'].unique():
        state_data = df[df['State'] == state]
        
        # Calculate yield stability (inverse of coefficient of variation)
        yield_mean = state_data['Yield_ton_per_ha'].mean()
        yield_std = state_data['Yield_ton_per_ha'].std()
        stability = 1 / (yield_std / yield_mean) if yield_mean > 0 else 0
        
        # Calculate yield growth trend
        yield_trend = np.polyfit(state_data['Year'], state_data['Yield_ton_per_ha'], 1)[0]
        
        capacity_data.append({
            'State': state,
            'Yield_Stability': stability,
            'Yield_Growth': yield_trend
        })
    
    capacity_df = pd.DataFrame(capacity_data)
    
    # Normalize
    capacity_df['Stability_Norm'] = (capacity_df['Yield_Stability'] - capacity_df['Yield_Stability'].min()) / \
                                     (capacity_df['Yield_Stability'].max() - capacity_df['Yield_Stability'].min())
    
    capacity_df['Growth_Norm'] = (capacity_df['Yield_Growth'] - capacity_df['Yield_Growth'].min()) / \
                                  (capacity_df['Yield_Growth'].max() - capacity_df['Yield_Growth'].min())
    
    # Combined adaptive capacity (higher is better)
    capacity_df['Adaptive_Capacity_Score'] = (capacity_df['Stability_Norm'] + capacity_df['Growth_Norm']) / 2
    
    print(f"✓ Adaptive capacity scores calculated for {len(capacity_df)} states")
    return capacity_df

def calculate_vulnerability_index(exposure_df, sensitivity_df, capacity_df):
    """Calculate final vulnerability index"""
    print("\nCalculating vulnerability index...")
    
    # Merge all components
    vulnerability_df = exposure_df[['State', 'Exposure_Score']].copy()
    vulnerability_df = vulnerability_df.merge(sensitivity_df[['State', 'Sensitivity_Score']], on='State')
    vulnerability_df = vulnerability_df.merge(capacity_df[['State', 'Adaptive_Capacity_Score']], on='State')
    
    # Vulnerability = Exposure + Sensitivity - Adaptive Capacity
    vulnerability_df['Vulnerability_Index'] = (
        vulnerability_df['Exposure_Score'] * 0.4 +
        vulnerability_df['Sensitivity_Score'] * 0.4 -
        vulnerability_df['Adaptive_Capacity_Score'] * 0.2
    )
    
    # Normalize to 0-100 scale
    min_val = vulnerability_df['Vulnerability_Index'].min()
    max_val = vulnerability_df['Vulnerability_Index'].max()
    vulnerability_df['Vulnerability_Index'] = ((vulnerability_df['Vulnerability_Index'] - min_val) / 
                                                (max_val - min_val)) * 100
    
    # Add risk categories
    vulnerability_df['Risk_Category'] = pd.cut(
        vulnerability_df['Vulnerability_Index'],
        bins=[0, 25, 50, 75, 100],
        labels=['Low', 'Moderate', 'High', 'Very High'],
        include_lowest=True
    )
    
    # Sort by vulnerability
    vulnerability_df = vulnerability_df.sort_values('Vulnerability_Index', ascending=False)
    
    print(f"✓ Vulnerability index calculated for {len(vulnerability_df)} states")
    return vulnerability_df

def visualize_vulnerability(vulnerability_df):
    """Create vulnerability visualizations"""
    print("\nCreating visualizations...")
    
    # Bar chart
    fig, ax = plt.subplots(figsize=(14, 8))
    
    colors = vulnerability_df['Risk_Category'].map({
        'Low': '#2ecc71',
        'Moderate': '#f39c12',
        'High': '#e67e22',
        'Very High': '#e74c3c'
    })
    
    bars = ax.barh(vulnerability_df['State'], vulnerability_df['Vulnerability_Index'], color=colors)
    
    ax.set_xlabel('Vulnerability Index (0-100)', fontsize=12, fontweight='bold')
    ax.set_ylabel('State', fontsize=12, fontweight='bold')
    ax.set_title('State-wise Agricultural Vulnerability to Climate Change', 
                 fontsize=14, fontweight='bold', pad=20)
    ax.grid(True, alpha=0.3, axis='x')
    
    # Add legend
    from matplotlib.patches import Patch
    legend_elements = [
        Patch(facecolor='#e74c3c', label='Very High Risk'),
        Patch(facecolor='#e67e22', label='High Risk'),
        Patch(facecolor='#f39c12', label='Moderate Risk'),
        Patch(facecolor='#2ecc71', label='Low Risk')
    ]
    ax.legend(handles=legend_elements, loc='lower right', fontsize=10)
    
    plt.tight_layout()
    plt.savefig('./visuals/vulnerability_index.png', dpi=300, bbox_inches='tight')
    print("✓ Saved: vulnerability_index.png")
    plt.close()
    
    # Component breakdown
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))
    fig.suptitle('Vulnerability Components by State', fontsize=14, fontweight='bold')
    
    top_10 = vulnerability_df.head(10)
    
    # Exposure
    axes[0].barh(top_10['State'], top_10['Exposure_Score'], color='#e74c3c')
    axes[0].set_title('Exposure Score', fontweight='bold')
    axes[0].set_xlabel('Score')
    axes[0].grid(True, alpha=0.3, axis='x')
    
    # Sensitivity
    axes[1].barh(top_10['State'], top_10['Sensitivity_Score'], color='#f39c12')
    axes[1].set_title('Sensitivity Score', fontweight='bold')
    axes[1].set_xlabel('Score')
    axes[1].grid(True, alpha=0.3, axis='x')
    
    # Adaptive Capacity
    axes[2].barh(top_10['State'], top_10['Adaptive_Capacity_Score'], color='#2ecc71')
    axes[2].set_title('Adaptive Capacity Score', fontweight='bold')
    axes[2].set_xlabel('Score')
    axes[2].grid(True, alpha=0.3, axis='x')
    
    plt.tight_layout()
    plt.savefig('./visuals/vulnerability_components.png', dpi=300, bbox_inches='tight')
    print("✓ Saved: vulnerability_components.png")
    plt.close()

def main():
    """Main execution function"""
    print("\n" + "="*60)
    print("Vulnerability Index Calculation")
    print("="*60 + "\n")
    
    # Load data
    df = load_data()
    
    # Calculate components
    exposure_df = calculate_exposure(df)
    sensitivity_df = calculate_sensitivity(df)
    capacity_df = calculate_adaptive_capacity(df)
    
    # Calculate vulnerability index
    vulnerability_df = calculate_vulnerability_index(exposure_df, sensitivity_df, capacity_df)
    
    # Save results
    vulnerability_df.to_csv('./data/processed/vulnerability_index.csv', index=False)
    print("\n✓ Saved: vulnerability_index.csv")
    
    # Print summary
    print("\n" + "="*60)
    print("Top 5 Most Vulnerable States:")
    print("="*60)
    print(vulnerability_df[['State', 'Vulnerability_Index', 'Risk_Category']].head().to_string(index=False))
    
    print("\n" + "="*60)
    print("Risk Category Distribution:")
    print("="*60)
    print(vulnerability_df['Risk_Category'].value_counts().to_string())
    
    # Visualize
    visualize_vulnerability(vulnerability_df)
    
    print("\n" + "="*60)
    print("Vulnerability analysis complete!")
    print("="*60)
    print("\nNext step: Run ml_model.py for predictive modeling\n")

if __name__ == "__main__":
    main()
